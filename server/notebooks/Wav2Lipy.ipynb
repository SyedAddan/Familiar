{"cells":[{"cell_type":"markdown","metadata":{"id":"sE22UQtQ9YYi"},"source":["# **Please use @justinjohn colab notebook which is better and actually works  https://colab.research.google.com/github/justinjohn0306/Wav2Lip/blob/master/Wav2Lip_simplified_v5.ipynb**\n","\n","# **There is no need for colab pro to use it.**\n","[Discord](https://discord.gg/F5WzXC8vXJ)\n"]},{"cell_type":"markdown","metadata":{"id":"dT9AQwdf8sJK"},"source":["\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"yJ5taGmPcWV-"},"source":["# **Get the code and models**"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"Qgo-oaI3JU2u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694501380780,"user_tz":-300,"elapsed":43271,"user":{"displayName":"i202438 Khawaja Muhammad Hassam Nazir","userId":"07532651612098312979"}},"outputId":"f9dd4ebf-4949-483d-b466-8889ce9e0612"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Done\n"]}],"source":["#@title <h1>Step1: Setup Wav2Lip</h1>\n","#@markdown * Install dependency\n","#@markdown * Download pretrained model\n","!rm -rf /content/sample_data\n","!mkdir /content/sample_data\n","\n","!git clone https://github.com/zabique/Wav2Lip\n","\n","#download the pretrained model\n","!wget 'https://iiitaphyd-my.sharepoint.com/personal/radrabha_m_research_iiit_ac_in/_layouts/15/download.aspx?share=EdjI7bZlgApMqsVoEUUXpLsBxqXbn5z8VTmoxp55YNDcIA' -O '/content/Wav2Lip/checkpoints/wav2lip_gan.pth'\n","a = !pip install https://raw.githubusercontent.com/AwaleSajil/ghc/master/ghc-1.0-py3-none-any.whl\n","\n","# !pip uninstall tensorflow tensorflow-gpu\n","!cd Wav2Lip && pip install -r requirements.txt\n","\n","#download pretrained model for face detection\n","!wget \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" -O \"/content/Wav2Lip/face_detection/detection/sfd/s3fd.pth\"\n","\n","!pip install -q youtube-dl\n","!pip install ffmpeg-python\n","!pip install librosa==0.9.1\n","\n","#this code for recording audio\n","\"\"\"\n","To write this piece of code I took inspiration/code from a lot of places.\n","It was late night, so I'm not sure how much I created or just copied o.O\n","Here are some of the possible references:\n","https://blog.addpipe.com/recording-audio-in-the-browser-using-pure-html5-and-minimal-javascript/\n","https://stackoverflow.com/a/18650249\n","https://hacks.mozilla.org/2014/06/easy-audio-capture-with-the-mediarecorder-api/\n","https://air.ghost.io/recording-to-an-audio-file-using-html5-and-js/\n","https://stackoverflow.com/a/49019356\n","\"\"\"\n","from IPython.display import HTML, Audio\n","from google.colab.output import eval_js\n","from base64 import b64decode\n","import numpy as np\n","from scipy.io.wavfile import read as wav_read\n","import io\n","import ffmpeg\n","\n","from IPython.display import clear_output\n","clear_output()\n","print(\"\\nDone\")"]},{"cell_type":"markdown","metadata":{"id":"vzokJMO19IyY"},"source":["\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"RgjaWJFs8B38"},"source":["# **Quick guide**\n","1. Create video file named input_video.mp4 - audio track removed\n","2. Create audio file named input_audio.wav\n","3. Both files have to be exact same length\n","4. Target face in the input_video.mp4, must be \"detectable\" in ALL videoframes (So no black or blurry frames etc)\n","5. Make sure u use correct file extensions\n","6. wav2lip does not like very long and high res clips (1080p/30seconds max)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"qdIQfY2Kswcb"},"source":["# **Now lets try!**"]},{"cell_type":"markdown","metadata":{"id":"9bDRYsfXTzXD"},"source":["\n","\n","---\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"cellView":"form","id":"vsphzJawLF-f","colab":{"base_uri":"https://localhost:8080/","height":142},"executionInfo":{"status":"ok","timestamp":1694501577877,"user_tz":-300,"elapsed":186449,"user":{"displayName":"i202438 Khawaja Muhammad Hassam Nazir","userId":"07532651612098312979"}},"outputId":"39c8206a-3588-4daf-e11e-b31cf91546ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/sample_data\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-c8ab3a81-b980-405c-be12-90cb37f084f8\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-c8ab3a81-b980-405c-be12-90cb37f084f8\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving input_video.mp4 to input_video.mp4\n","Saving input_audio.wav to input_audio.wav\n","/content\n"]}],"source":["#@title 1.Upload input_video.mp4 & input_audio.wav files\n","%cd sample_data/\n","from google.colab import files\n","uploaded = files.upload()\n","%cd .."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"jR5utmDMcSZY","executionInfo":{"status":"ok","timestamp":1694501911616,"user_tz":-300,"elapsed":328752,"user":{"displayName":"i202438 Khawaja Muhammad Hassam Nazir","userId":"07532651612098312979"}},"outputId":"82753ed6-f1de-460c-eb2b-71dda6c17bac","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Using cuda for inference.\n","Reading video frames...\n","Number of frames available for inference: 206\n","/content/Wav2Lip/audio.py:100: FutureWarning: Pass sr=16000, n_fft=800 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n","  return librosa.filters.mel(hp.sample_rate, hp.n_fft, n_mels=hp.num_mels,\n","(80, 593)\n","Length of mel chunks: 218\n","  0% 0/2 [00:00<?, ?it/s]\n","  0% 0/13 [00:00<?, ?it/s]\u001b[A\n","  8% 1/13 [03:27<41:28, 207.37s/it]\u001b[A\n"," 15% 2/13 [03:30<16:00, 87.30s/it] \u001b[A\n"," 23% 3/13 [03:33<08:07, 48.79s/it]\u001b[A\n"," 31% 4/13 [03:36<04:36, 30.70s/it]\u001b[A\n"," 38% 5/13 [03:39<02:46, 20.77s/it]\u001b[A\n"," 46% 6/13 [03:42<01:43, 14.80s/it]\u001b[A\n"," 54% 7/13 [03:45<01:05, 10.92s/it]\u001b[A\n"," 62% 8/13 [03:48<00:41,  8.39s/it]\u001b[A\n"," 69% 9/13 [03:51<00:26,  6.74s/it]\u001b[A\n"," 77% 10/13 [03:55<00:17,  5.68s/it]\u001b[A\n"," 85% 11/13 [03:58<00:09,  4.84s/it]\u001b[A\n"," 92% 12/13 [04:01<00:04,  4.26s/it]\u001b[A\n","100% 13/13 [04:38<00:00, 21.41s/it]\n","Load checkpoint from: checkpoints/wav2lip_gan.pth\n","Model loaded\n","100% 2/2 [05:01<00:00, 150.81s/it]\n","ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n","  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n","  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n","  libavutil      56. 70.100 / 56. 70.100\n","  libavcodec     58.134.100 / 58.134.100\n","  libavformat    58. 76.100 / 58. 76.100\n","  libavdevice    58. 13.100 / 58. 13.100\n","  libavfilter     7.110.100 /  7.110.100\n","  libswscale      5.  9.100 /  5.  9.100\n","  libswresample   3.  9.100 /  3.  9.100\n","  libpostproc    55.  9.100 / 55.  9.100\n","\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : stereo\n","\u001b[0mInput #0, wav, from '/content/sample_data/input_audio.wav':\n","  Duration: 00:00:07.40, bitrate: 1536 kb/s\n","  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, stereo, s16, 1536 kb/s\n","Input #1, avi, from 'temp/result.avi':\n","  Metadata:\n","    software        : Lavf59.27.100\n","  Duration: 00:00:07.27, start: 0.000000, bitrate: 3102 kb/s\n","  Stream #1:0: Video: mpeg4 (Simple Profile) (DIVX / 0x58564944), yuv420p, 1280x720 [SAR 1:1 DAR 16:9], 3104 kb/s, 30 fps, 30 tbr, 30 tbn, 30 tbc\n","Stream mapping:\n","  Stream #1:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n","  Stream #0:0 -> #0:1 (pcm_s16le (native) -> aac (native))\n","Press [q] to stop, [?] for help\n","\u001b[1;36m[libx264 @ 0x5c2fe1386680] \u001b[0m\u001b[0;33m-qscale is ignored, -crf is recommended.\n","\u001b[0m\u001b[1;36m[libx264 @ 0x5c2fe1386680] \u001b[0musing SAR=1/1\n","\u001b[1;36m[libx264 @ 0x5c2fe1386680] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2 AVX512\n","\u001b[1;36m[libx264 @ 0x5c2fe1386680] \u001b[0mprofile High, level 3.1, 4:2:0, 8-bit\n","\u001b[1;36m[libx264 @ 0x5c2fe1386680] \u001b[0m264 - core 163 r3060 5db6aa6 - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n","Output #0, mp4, to 'results/result_voice.mp4':\n","  Metadata:\n","    encoder         : Lavf58.76.100\n","  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 1280x720 [SAR 1:1 DAR 16:9], q=2-31, 30 fps, 15360 tbn\n","    Metadata:\n","      encoder         : Lavc58.134.100 libx264\n","    Side data:\n","      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n","  Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 128 kb/s\n","    Metadata:\n","      encoder         : Lavc58.134.100 aac\n","frame=  218 fps= 16 q=-1.0 Lsize=    1410kB time=00:00:07.38 bitrate=1564.5kbits/s speed=0.553x    \n","video:1294kB audio:107kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.636793%\n","\u001b[1;36m[libx264 @ 0x5c2fe1386680] \u001b[0mframe I:1     Avg QP:21.16  size: 22015\n","\u001b[1;36m[libx264 @ 0x5c2fe1386680] \u001b[0mframe P:101   Avg QP:21.20  size:  9209\n","\u001b[1;36m[libx264 @ 0x5c2fe1386680] \u001b[0mframe B:116   Avg QP:22.09  size:  3208\n","\u001b[1;36m[libx264 @ 0x5c2fe1386680] \u001b[0mconsecutive B-frames: 22.9% 13.8% 13.8% 49.5%\n","\u001b[1;36m[libx264 @ 0x5c2fe1386680] \u001b[0mmb I  I16..4: 31.9% 67.3%  0.8%\n","\u001b[1;36m[libx264 @ 0x5c2fe1386680] \u001b[0mmb P  I16..4:  5.4% 15.9%  0.0%  P16..4: 45.7%  4.9%  3.4%  0.0%  0.0%    skip:24.5%\n","\u001b[1;36m[libx264 @ 0x5c2fe1386680] \u001b[0mmb B  I16..4:  0.8%  2.4%  0.0%  B16..8: 36.3%  1.3%  0.0%  direct: 1.9%  skip:57.3%  L0:59.5% L1:40.0% BI: 0.6%\n","\u001b[1;36m[libx264 @ 0x5c2fe1386680] \u001b[0m8x8 transform intra:74.3% inter:91.7%\n","\u001b[1;36m[libx264 @ 0x5c2fe1386680] \u001b[0mcoded y,uvDC,uvAC intra: 32.4% 53.5% 1.1% inter: 6.5% 16.7% 0.0%\n","\u001b[1;36m[libx264 @ 0x5c2fe1386680] \u001b[0mi16 v,h,dc,p: 26% 28% 28% 18%\n","\u001b[1;36m[libx264 @ 0x5c2fe1386680] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 24% 26% 47%  1%  0%  0%  0%  0%  1%\n","\u001b[1;36m[libx264 @ 0x5c2fe1386680] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 50% 19% 13%  2%  3%  6%  4%  2%  1%\n","\u001b[1;36m[libx264 @ 0x5c2fe1386680] \u001b[0mi8c dc,h,v,p: 46% 27% 25%  2%\n","\u001b[1;36m[libx264 @ 0x5c2fe1386680] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n","\u001b[1;36m[libx264 @ 0x5c2fe1386680] \u001b[0mref P L0: 65.3%  4.1% 20.6% 10.1%\n","\u001b[1;36m[libx264 @ 0x5c2fe1386680] \u001b[0mref B L0: 77.5% 17.5%  5.0%\n","\u001b[1;36m[libx264 @ 0x5c2fe1386680] \u001b[0mref B L1: 93.4%  6.6%\n","\u001b[1;36m[libx264 @ 0x5c2fe1386680] \u001b[0mkb/s:1457.94\n","\u001b[1;36m[aac @ 0x5c2fe13881c0] \u001b[0mQavg: 25897.943\n"]}],"source":["#@title 2.Create Wav2Lip video (using wav2lip_gan.pth) GAN\n","!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"/content/sample_data/input_video.mp4\" --audio \"/content/sample_data/input_audio.wav\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"WxbzXZvLliiA"},"outputs":[],"source":["#@title 3.Play result video -  50% scaling\n","from IPython.display import HTML\n","from base64 import b64encode\n","mp4 = open('/content/Wav2Lip/results/result_voice.mp4','rb').read()\n","data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","HTML(f\"\"\"\n","<video width=\"50%\" height=\"50%\" controls>\n","      <source src=\"{data_url}\" type=\"video/mp4\">\n","</video>\"\"\")"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1694501939612,"user":{"displayName":"i202438 Khawaja Muhammad Hassam Nazir","userId":"07532651612098312979"},"user_tz":-300},"id":"1kt-krsEbz5j","outputId":"2d128fac-d00e-4d09-8ba9-41683a811eb6"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_6065748f-9001-4d8b-9589-badabbaf2310\", \"result_voice.mp4\", 1443508)"]},"metadata":{}}],"source":["#@title 4.Download Result.mp4 to your computer\n","from google.colab import files\n","files.download('/content/Wav2Lip/results/result_voice.mp4')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"fT8njpBCJ7gD"},"outputs":[],"source":["#@title 5. Delete old uploaded samples & result files, so you can start over again.\n","%rm /content/sample_data/*\n","%rm /content/Wav2Lip/results/*\n","from IPython.display import clear_output\n","clear_output()\n","print(\"\\nDone! now press X\")"]},{"cell_type":"markdown","metadata":{"id":"BgMkHOFqT2fK"},"source":["\n","\n","---\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"background_save":true},"id":"2OhT0w2uT4rQ"},"outputs":[],"source":["#@title 1-4. Batch processing - Upload -> process -> download -> play result\n","%cd sample_data/\n","%rm input_audio.wav\n","%rm input_video.mp4\n","from google.colab import files\n","uploaded = files.upload()\n","%cd ..\n","!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"/content/sample_data/input_video.mp4\" --audio \"/content/sample_data/input_audio.wav\"\n","from google.colab import files\n","files.download('/content/Wav2Lip/results/result_voice.mp4')\n","from IPython.display import HTML\n","from base64 import b64encode\n","mp4 = open('/content/Wav2Lip/results/result_voice.mp4','rb').read()\n","data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","HTML(f\"\"\"\n","<video width=\"50%\" height=\"50%\" controls>\n","      <source src=\"{data_url}\" type=\"video/mp4\">\n","</video>\"\"\")"]},{"cell_type":"markdown","metadata":{"id":"q9NvwrJ3vRcs"},"source":["\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"d7zgfrQqbKom"},"source":["# **Variations to try**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"xw0xFtZ2bsx8"},"outputs":[],"source":["#@title 2.Use resize_factor to reduce the video resolution, as there is a change you might get better results for lower resolution videos. Why? Because the model was trained on low resolution faces.\n","!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"/content/sample_data/input_video.mp4\" --audio \"/content/sample_data/input_audio.wav\" --resize_factor 2"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"45XW4SZAzIz5"},"outputs":[],"source":["#@title 3.Use more padding to include the chin region (u can manually edit pads dimensions viewing and changing the code)\n","!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"/content/sample_data/input_video.mp4\" --audio \"/content/sample_data/input_audio.wav\" --pads 0 20 0 0"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"background_save":true},"id":"X1Z0zRdZR5BZ"},"outputs":[],"source":["#@title 4.Play result video -  50% scaling\n","from IPython.display import HTML\n","from base64 import b64encode\n","mp4 = open('/content/Wav2Lip/results/result_voice.mp4','rb').read()\n","data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","HTML(f\"\"\"\n","<video width=\"50%\" height=\"50%\" controls>\n","      <source src=\"{data_url}\" type=\"video/mp4\">\n","</video>\"\"\")"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"gfXFOpAmR_dh"},"outputs":[],"source":["#@title 5.Download Result.mp4 to your computer\n","from google.colab import files\n","files.download('/content/Wav2Lip/results/result_voice.mp4')\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1IjFW1cLevs6Ouyu4Yht4mnR4yeuMqO7Y","timestamp":1694502371117},{"file_id":"1_EQJ5DPLfOPufsy26H5PCSVKr43A7KiC","timestamp":1620993149816},{"file_id":"1tZpDWXz49W6wDcTprANRGLo2D_EbD5J8","timestamp":1620984500069},{"file_id":"1NLUwupCBsB1HrpEmOIHeMgU63sus2LxP","timestamp":1597735440478}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}