{"cells":[{"cell_type":"markdown","id":"30e0a75b","metadata":{"id":"30e0a75b"},"source":["### This notebook is optionally accelerated with a GPU runtime.\n","### If you would like to use this acceleration, please select the menu option \"Runtime\" -> \"Change runtime type\", select \"Hardware Accelerator\" -> \"GPU\" and click \"SAVE\"\n","\n","----------------------------------------------------------------------\n","\n","# Silero Speech-To-Text Models\n","\n","*Author: Silero AI Team*\n","\n","**A set of compact enterprise-grade pre-trained STT Models for multiple languages.**\n","\n","_ | _\n","- | -\n","![alt](https://pytorch.org/assets/images/silero_stt_model.jpg) | ![alt](https://pytorch.org/assets/images/silero_imagenet_moment.png)"]},{"cell_type":"code","execution_count":null,"id":"0b4adf4d","metadata":{"id":"0b4adf4d","executionInfo":{"status":"ok","timestamp":1693148313564,"user_tz":-300,"elapsed":7160,"user":{"displayName":"","userId":""}},"outputId":"310c699e-c9ca-404b-9a9a-bda8c187e18f","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.5/79.5 kB 1.9 MB/s eta 0:00:00\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 117.0/117.0 kB 5.7 MB/s eta 0:00:00\n"]}],"source":["%%bash\n","# this assumes that you have a proper version of PyTorch already installed\n","pip install -q torchaudio omegaconf soundfile"]},{"cell_type":"code","execution_count":null,"id":"247efa84","metadata":{"id":"247efa84","executionInfo":{"status":"ok","timestamp":1693148437563,"user_tz":-300,"elapsed":2342,"user":{"displayName":"","userId":""}},"outputId":"5921b15b-dc8a-482d-a51c-71ea9594b721","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stderr","text":["Using cache found in /root/.cache/torch/hub/snakers4_silero-models_master\n","100%|██████████| 0.99M/0.99M [00:00<00:00, 2.71MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["how you what are you doing\n"]}],"source":["import torch\n","import zipfile\n","import torchaudio\n","from glob import glob\n","\n","device = torch.device('cpu')  # gpu also works, but our models are fast enough for CPU\n","\n","model, decoder, utils = torch.hub.load(repo_or_dir='snakers4/silero-models',\n","                                       model='silero_stt',\n","                                       language='en', # also available 'de', 'es'\n","                                       device=device)\n","(read_batch, split_into_batches,\n"," read_audio, prepare_model_input) = utils  # see function signature for details\n","\n","# download a single file, any format compatible with TorchAudio (soundfile backend)\n","torch.hub.download_url_to_file('https://opus-codec.org/static/examples/samples/speech_orig.wav',\n","                               dst ='speech_orig.wav', progress=True)\n","test_files = glob('Recording.wav')\n","batches = split_into_batches(test_files, batch_size=10)\n","input = prepare_model_input(read_batch(batches[0]),\n","                            device=device)\n","\n","output = model(input)\n","for example in output:\n","    print(decoder(example.cpu()))"]},{"cell_type":"markdown","id":"86297a20","metadata":{"id":"86297a20"},"source":["### Model Description\n","\n","Silero Speech-To-Text models provide enterprise grade STT in a compact form-factor for several commonly spoken languages. Unlike conventional ASR models our models are robust to a variety of dialects, codecs, domains, noises, lower sampling rates (for simplicity audio should be resampled to 16 kHz). The models consume a normalized audio in the form of samples (i.e. without any pre-processing except for normalization to -1 ... 1) and output frames with token probabilities. We provide a decoder utility for simplicity (we could include it into our model itself, but scripted modules had problems with storing model artifacts i.e. labels during certain export scenarios).\n","\n","We hope that our efforts with Open-STT and Silero Models will bring the ImageNet moment in speech closer.\n","\n","### Supported Languages and Formats\n","\n","As of this page update, the following languages are supported:\n","\n","- English\n","- German\n","- Spanish\n","\n","To see the always up-to-date language list, please visit our [repo](https://github.com/snakers4/silero-models) and see the `yml` [file](https://github.com/snakers4/silero-models/blob/master/models.yml) for all available checkpoints.\n","\n","### Additional Examples and Benchmarks\n","\n","For additional examples and other model formats please visit this [link](https://github.com/snakers4/silero-models). For quality and performance benchmarks please see the [wiki](https://github.com/snakers4/silero-models/wiki). These resources will be updated from time to time.\n","\n","### References\n","\n","- [Silero Models](https://github.com/snakers4/silero-models)\n","- [Alexander Veysov, \"Toward's an ImageNet Moment for Speech-to-Text\", The Gradient, 2020](https://thegradient.pub/towards-an-imagenet-moment-for-speech-to-text/)\n","- [Alexander Veysov, \"A Speech-To-Text Practitioner’s Criticisms of Industry and Academia\", The Gradient, 2020](https://thegradient.pub/a-speech-to-text-practitioners-criticisms-of-industry-and-academia/)"]}],"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/pytorch/pytorch.github.io/blob/master/assets/hub/snakers4_silero-models_stt.ipynb","timestamp":1693148519507}]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}