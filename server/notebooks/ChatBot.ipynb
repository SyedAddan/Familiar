{"cells":[{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13858,"status":"ok","timestamp":1694029528207,"user":{"displayName":"i202438 Khawaja Muhammad Hassam Nazir","userId":"07532651612098312979"},"user_tz":-300},"id":"nsOw5AP85MMP","outputId":"0e341b12-8084-4797-865c-f0f4e197d68b"},"outputs":[{"name":"stdout","output_type":"stream","text":["HELLO HOW ARE YOU WHAT ARE YOU DOING\n"]}],"source":["import soundfile as sf\n","from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer\n","import torch\n","audio_file = \"/content/Recording.wav\"\n","\n","# Load the audio signal\n","waveform, sample_rate = sf.read(audio_file)\n","\n","# Resample audio to match expected sampling rate of the model\n","if sample_rate != 16000:\n","    # Resample the waveform using scipy.signal.resample\n","    from scipy import signal\n","    waveform = signal.resample(waveform, int(waveform.shape[0] * 16000 / sample_rate))\n","    sample_rate = 16000\n","\n","# Check that the input audio signal has the expected shape\n","if waveform.ndim != 1:\n","    waveform = waveform[:, 0]\n","\n","# Check that the audio signal is preprocessed according to the model's requirements\n","if (waveform.max() > 1) or (waveform.min() < -1):\n","    waveform = waveform / max(abs(waveform))\n","#Initialize the model and tokenizer\n","model = Wav2Vec2ForCTC.from_pretrained(\"/content/drive/MyDrive/Pretrained_models/wav2\")\n","tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"/content/drive/MyDrive/Pretrained_models/wav2tok\")\n","\n","# Encode the input audio as a sequence of tokens\n","input_values = tokenizer(waveform, return_tensors=\"pt\").input_values.squeeze()\n","\n","# Perform transcription\n","with torch.no_grad():\n","    logits = model(input_values.unsqueeze(0)).logits\n","predicted_ids = torch.argmax(logits, dim=-1)\n","transcription = tokenizer.decode(predicted_ids[0])\n","print(transcription)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":12167,"status":"ok","timestamp":1694029545956,"user":{"displayName":"i202438 Khawaja Muhammad Hassam Nazir","userId":"07532651612098312979"},"user_tz":-300},"id":"cDOjAnGY54SV"},"outputs":[],"source":["from transformers import GPT2Tokenizer, GPT2LMHeadModel\n","import torch\n","tokenizer = GPT2Tokenizer.from_pretrained(\"af1tang/personaGPT\", padding_side='left')\n","model = GPT2LMHeadModel.from_pretrained(\"af1tang/personaGPT\")\n","if torch.cuda.is_available():\n","    model = model.cuda()"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["flatten = lambda l: [item for sublist in l for item in sublist]\n","\n","def to_data(x):\n","    if torch.cuda.is_available():\n","        x = x.cpu()\n","    return x.data.numpy()\n","\n","def to_var(x):\n","    if not torch.is_tensor(x):\n","        x = torch.Tensor(x)\n","    if torch.cuda.is_available():\n","        x = x.cuda()\n","    return x\n","\n","def display_dialog_history(dialog_hx):\n","    for j, line in enumerate(dialog_hx):\n","        msg = tokenizer.decode(line)\n","        if j%2 == 0:\n","            print(\">> User: \"+ msg)\n","        else:\n","            print(\">> Bot: \"+msg)\n","            print()\n","\n","def generate_next(bot_input_ids, do_sample=True, top_k=10, top_p=.92, max_length=1000, pad_token=tokenizer.eos_token_id):\n","    full_msg = model.generate(bot_input_ids, do_sample=True,\n","                                              top_k=top_k, top_p=top_p,\n","                                              max_length=max_length, pad_token_id=tokenizer.eos_token_id)\n","    msg = to_data(full_msg.detach()[0])[bot_input_ids.shape[-1]:]\n","    return msg"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14094,"status":"ok","timestamp":1694029574068,"user":{"displayName":"i202438 Khawaja Muhammad Hassam Nazir","userId":"07532651612098312979"},"user_tz":-300},"id":"7uIsU-RT8hVd","outputId":"1e7d66ea-03fe-4578-9cd1-41748645d61b"},"outputs":[{"name":"stdout","output_type":"stream","text":[">> Enter the facts about the bot (Press Escape or Leave Blank and press Enter to Finish Writing)\n"]}],"source":["# get personality facts for conversation\n","personas = [f\"Listed below are the facts about the bot, the bot has to abide by these rules and never go astray from the facts provided below {tokenizer.eos_token}\"]\n","i = 0\n","print(\">> Enter the facts about the bot (Press Escape or Leave Blank and press Enter to Finish Writing)\")\n","while True:\n","    i += 1\n","    response = input(f\">> Fact {i}: \")\n","    if response == \"\":\n","        break\n","    response += tokenizer.eos_token\n","    personas.append(response)\n","personas = tokenizer.encode(''.join(['<|p2|>'] + personas + ['<|sep|>'] + ['<|start|>']))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":718,"status":"ok","timestamp":1694029579092,"user":{"displayName":"i202438 Khawaja Muhammad Hassam Nazir","userId":"07532651612098312979"},"user_tz":-300},"id":"FROPc1bzAaMV","outputId":"e23ed85d-9c09-4e9b-8f14-57d285b36501"},"outputs":[],"source":["# converse for 8 turns\n","dialog_hx = []\n","for step in range(8):\n","    # encode the user input\n","    transcription = input(\">> User: \").strip()\n","    user_inp = tokenizer.encode(\">> User: \" + transcription + tokenizer.eos_token)\n","    # append to the chat history\n","    dialog_hx.append(user_inp)\n","\n","    # generated a response while limiting the total chat history to 1000 tokens,\n","    bot_input_ids = to_var([personas + flatten(dialog_hx)]).long()\n","    msg = generate_next(bot_input_ids)\n","    dialog_hx.append(msg)\n","    print(\"Bot: {}\".format(tokenizer.decode(msg, skip_special_tokens=True)))\n"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"3KjvYpE6AqNM"},"outputs":[{"name":"stdout","output_type":"stream","text":[">> User: >> User: Hello mom<|endoftext|>\n",">> Bot: hello how are you doing?<|endoftext|>\n","\n"]}],"source":["display_dialog_history(dialog_hx)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPx83Uwx1o7aSPAu6BCWl+e","gpuType":"T4","mount_file_id":"1HvyvUHCecLk_q_znkPlO8bVnBoPNjVKg","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
